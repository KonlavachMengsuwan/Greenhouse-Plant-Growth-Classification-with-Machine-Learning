# üå± Greenhouse Plant Growth Classification with Machine Learning

This project applies **machine learning** to classify greenhouse-grown plants based on growth metrics. We use a **tabular dataset of plant measurements** from two types of greenhouses: **Traditional** and **IoT-based.**

---

## üìù **Objective**

üëâ Predict the **type of greenhouse environment** (traditional or IoT-based) based on plant physiological and growth metrics.

We explore:
- Data exploration & visualization
- Feature correlation
- Machine learning classification
- Model evaluation

---

## üìä **Dataset Description**

The dataset contains **30,000 samples** of plant growth measurements across 6 experimental classes:

| Class | Description              |
|:------|:------------------------|
| SA     | Traditional Greenhouse A |
| SB     | Traditional Greenhouse B |
| SC     | Traditional Greenhouse C |
| TA     | IoT Greenhouse A         |
| TB     | IoT Greenhouse B         |
| TC     | IoT Greenhouse C         |

### **Features:**

| Column | Description |
|:--------|:------------|
| ACHP | Avg chlorophyll content per plant |
| PHR  | Plant height rate |
| AWWGV| Avg wet weight of vegetative growth |
| ALAP | Avg leaf area per plant |
| ANPL | Avg number of leaves per plant |
| ARD  | Avg root diameter |
| ADWR | Avg dry weight of roots |
| PDMVG| % dry matter in vegetative growth |
| ARL  | Avg root length |
| AWWR | Avg wet weight of roots |
| ADWV | Avg dry weight of vegetative parts |
| PDMRG| % dry matter in root growth |
| Class | Experimental class (target) |

---

## üïµÔ∏è‚Äç‚ôÇÔ∏è **Exploratory Data Analysis (EDA)**

We began by:
‚úÖ Checking class balance  
‚úÖ Summarizing features  
‚úÖ Correlation heatmap  
‚úÖ Visualizing feature distributions per class

---

### **Key Insights from EDA**

üîç **1. Class distribution:**
- The dataset is **perfectly balanced**: 5000 samples per class.
- No resampling required.

üîç **2. Descriptive statistics:**
- All features are numeric, no missing values.
- Wide range in some features (e.g., `ALAP`, `AWWR`) ‚Üí scaling may be required.

üîç **3. Correlation analysis:**
- Strong positive correlations:
  - `AWWGV` ‚Üî `ALAP` (**r ‚âà 0.95**) ‚Üí more leaf area correlates with vegetative weight.
  - `ADWR` ‚Üî `AWWR` (**r ‚âà 0.93**)
  - `ADWV` ‚Üî `PDMVG` (**r ‚âà 0.88**)
- Multicollinearity likely ‚Üí may need to handle in some models.

üîç **4. Boxplots per Class:**
- Features like `ACHP`, `PHR`, `ALAP` show noticeable separation between classes.
- Features like `ANPL`, `AWWGV` show overlap ‚Üí less discriminatory power alone.
- Suggests classification will benefit from combining multiple features.

---

### **EDA Code**

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('Greenhouse Plant Growth Metrics.csv')

# Preview
print(df.head())

# Class balance
print(df['Class'].value_counts())

# Descriptive stats
print(df.describe())

# Correlation heatmap
plt.figure(figsize=(12, 10))
corr = df.drop(columns=['Random']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Boxplots for selected features
features = ['ACHP', 'PHR', 'AWWGV', 'ALAP', 'ANPL']
for feat in features:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x='Class', y=feat, data=df)
    plt.title(f'{feat} distribution by Class')
    plt.show()
```

### EDA Plots
![1_Correlation](https://github.com/user-attachments/assets/cb89a9d4-c84f-4497-9d64-aecd42c08b1c)
![2](https://github.com/user-attachments/assets/f0ef0700-1a1a-4562-9f49-6522c423ba14)
![3](https://github.com/user-attachments/assets/c7cdca6a-a29d-4c96-8e4c-71c6c2fd9aa0)
![4](https://github.com/user-attachments/assets/338aa432-b89f-4bdd-ba82-7ec0aecd6a8a)
![5](https://github.com/user-attachments/assets/568b3bc2-b1aa-4048-85b3-26c5c048edae)
![6](https://github.com/user-attachments/assets/144a7a54-53f4-4a7b-8aca-43a0efcceb72)

## üõ†Ô∏è **2. Data Preprocessing**

After completing exploratory data analysis, we prepared the dataset for machine learning:

‚úÖ Dropped the `Random` column ‚Üí this identifier does not provide predictive information.

‚úÖ Encoded the categorical target variable `Class` into numeric labels:

| Original Class | Encoded |
|:---------------|:--------|
| SA              | 0       |
| SB              | 1       |
| SC              | 2       |
| TA              | 3       |
| TB              | 4       |
| TC              | 5       |

‚úÖ Scaled the numeric features using **StandardScaler** ‚Üí ensures features have zero mean and unit variance, improving performance for distance-based algorithms.

‚úÖ Prepared:
- Feature matrix `X_scaled`: shape **(30,000 samples, 12 features)**
- Target vector `y`: encoded class labels

---

### **Preprocessing Code**

```python
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Drop irrelevant column
df_clean = df.drop(columns=['Random'])

# Encode target labels
label_encoder = LabelEncoder()
df_clean['Class_encoded'] = label_encoder.fit_transform(df_clean['Class'])

# Prepare features and target
X = df_clean.drop(columns=['Class', 'Class_encoded'])
y = df_clean['Class_encoded']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Mapping of class labels
class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print("Class mapping:", class_mapping)
```

‚úÖ The encoded class mapping is:
```
{'SA': 0, 'SB': 1, 'SC': 2, 'TA': 3, 'TB': 4, 'TC': 5}
```

The dataset is now clean, numeric, and scaled‚Äîready for machine learning modeling!

## ü§ñ **3. Machine Learning Modeling**

We trained and evaluated three machine learning models for **multiclass classification** (6 classes):

‚úÖ Logistic Regression (multinomial)  
‚úÖ Random Forest Classifier  
‚úÖ XGBoost Classifier

All models were trained using:
- Feature matrix: **12 scaled numeric features**
- Target: **encoded Class label (0‚Äì5)**
- **Train-test split:** 80% train / 20% test (stratified)

---

### **Model Training Code**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
    plt.title(f'{name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
```

### **Results**

All three machine learning models achieved **perfect accuracy on the test set**:

| Model                | Accuracy |
|---------------------|----------|
| Logistic Regression  | 1.0000   |
| Random Forest        | 1.0000   |
| XGBoost              | 1.0000   |

‚úÖ Every sample in the test set was correctly classified.  
‚úÖ The precision, recall, and F1-score for each class were all **1.00**.  
‚úÖ Confusion matrices showed **zero misclassifications across all classes.**

---

### **Interpretation**

Achieving **100% accuracy on both training and unseen test data** is highly unusual in real-world machine learning tasks. This suggests:

- The dataset has **very strong and easily separable patterns** between classes.
- One or more features might be **highly correlated** with the target class, making classification very straightforward.
- There may be **redundant or potentially leaking features** (features that act as proxies for the class label).

In the context of this dataset‚Äîcollected from controlled greenhouse experiments‚Äîit‚Äôs plausible that the data is inherently clean, structured, and highly separable.

Despite the perfect accuracy, it‚Äôs important to further analyze **feature importance** to understand which features are driving the predictions and whether the model is overly reliant on a small subset of variables.











